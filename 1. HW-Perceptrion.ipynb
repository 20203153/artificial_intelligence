{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install numpy matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.loadtxt('perceptron_toydata.txt')\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, Y = data[:, :2], data[:, 2]\n",
    "X = np.insert(X, obj=0, values=1, axis=1)\n",
    "Y = (Y - 0.5) * 2\n",
    "\n",
    "print(X)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(X[Y == -1, 1], X[Y == -1, 2], label=\"class -1\")\n",
    "plt.scatter(X[Y == 1, 1], X[Y == 1, 2], label=\"class +1\")\n",
    "plt.title(\"Data plot\")\n",
    "plt.xlabel(\"feature 1\")\n",
    "plt.ylabel(\"feature 2\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perceptrion start"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    def __init__(self, weights = 3):\n",
    "        self.weights = weights\n",
    "        np.random.seed(4)\n",
    "        self.W = np.random.randn(self.weights)\n",
    "        self.lr = 2e-3\n",
    "    \n",
    "    def evaluate(self, X: np.ndarray, Y: np.ndarray, debug: bool = False) -> np.ndarray:\n",
    "        # np.dot is dot-product of vector/matrix. is equals vector/matrix multify.\n",
    "        # 1 if np.dot() >= 0 else -1 is equals np.where(x >= 0, 1, -1)\n",
    "        wsum = [1 if np.dot(X[i], self.W) >= 0 else -1 for i in range(X.shape[0])]\n",
    "        \n",
    "        # wrong Y label is stored.\n",
    "        self.Y = [i for i in range(X.shape[0]) if wsum[i] != Y[i]]\n",
    "\n",
    "        if debug:\n",
    "            print(f\"{len(X)- len(self.Y)} sample are correctly classified, {len(self.Y)} sample are incorrectly classified\")\n",
    "\n",
    "    def train(self, X: np.ndarray, Y: np.ndarray):\n",
    "        W = np.zeros(self.W.shape[0])\n",
    "\n",
    "        for i in self.Y:\n",
    "            for j in range(self.W.shape[0]):\n",
    "                W[j] += Y[i] * X[i,j]\n",
    "        \n",
    "        self.W += self.lr * W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perceptron = Perceptron()\n",
    "\n",
    "perceptron.evaluate(X, Y, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_min = -4\n",
    "x2_min = -(perceptron.W[0] + perceptron.W[1] * x1_min) / perceptron.W[2]\n",
    "x1_max = 4\n",
    "x2_max = -(perceptron.W[0] + perceptron.W[1] * x1_max) / perceptron.W[2]\n",
    "\n",
    "plt.plot([x1_min, x1_max], [x2_min, x2_max])\n",
    "plt.scatter(X[Y == -1, 1], X[Y == -1, 2], label=\"class -1\")\n",
    "plt.scatter(X[Y == 1, 1], X[Y == 1, 2], label=\"class +1\")\n",
    "plt.title('Before training')\n",
    "plt.xlabel('feature 1')\n",
    "plt.ylabel('feature 2')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(100):\n",
    "    perceptron.train(X, Y)\n",
    "    perceptron.evaluate(X, Y, True)\n",
    "\n",
    "print(perceptron.W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1_min = -4\n",
    "x2_min = -(perceptron.W[0] + perceptron.W[1] * x1_min) / perceptron.W[2]\n",
    "x1_max = 4\n",
    "x2_max = -(perceptron.W[0] + perceptron.W[1] * x1_max) / perceptron.W[2]\n",
    "\n",
    "plt.plot([x1_min, x1_max], [x2_min, x2_max])\n",
    "plt.scatter(X[Y == -1, 1], X[Y == -1, 2], label=\"class -1\")\n",
    "plt.scatter(X[Y == 1, 1], X[Y == 1, 2], label=\"class +1\")\n",
    "plt.title('Before training')\n",
    "plt.xlabel('feature 1')\n",
    "plt.ylabel('featore 2')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.loadtxt('perceptron_toydata.txt')\n",
    "X, Y = data[:, :2], data[:, 2]\n",
    "X = np.insert(X, obj=0, values=1, axis=1)\n",
    "Y = (Y - 0.5) * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PerceptronVectorized:\n",
    "    def __init__(self, weights = 3):\n",
    "        self.weights = weights\n",
    "        np.random.seed(4)\n",
    "        self.W = np.random.randn(self.weights)\n",
    "        self.lr = 2e-3\n",
    "    \n",
    "    def evaluate(self, X: np.ndarray, Y: np.ndarray, debug: bool = False) -> np.ndarray:\n",
    "        # np.dot is dot-product of vector/matrix. is equals vector/matrix multify.\n",
    "        # wsum = [1 if np.dot(X[i], self.W) >= 0 else -1 for i in range(X.shape[0])]\n",
    "        # self.Y = [i for i in range(X.shape[0]) if wsum[i] != Y[i]]\n",
    "\n",
    "        w_sum = np.dot(X, self.W)\n",
    "        # np.where is \n",
    "        y_pred = np.where(w_sum >= 0, 1, -1)\n",
    "\n",
    "        if debug:\n",
    "            print(f\"{len(X) - np.sum([y_pred != Y])} sample are correctly classified, {np.sum([y_pred != Y])} samples are incorrectly classified\")\n",
    "\n",
    "    def train(self, X: np.ndarray, Y: np.ndarray):\n",
    "        W = np.einsum('i,ij->j', Y, X)\n",
    "        # W[j] += Y[i] * X[i,j]\n",
    "        \n",
    "        self.W += self.lr * W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perceptron2 = PerceptronVectorized()\n",
    "perceptron2.evaluate(X, Y, True)\n",
    "\n",
    "x1_min = -4\n",
    "x2_min = -(perceptron2.W[0] + perceptron2.W[1] * x1_min) / perceptron2.W[2]\n",
    "x1_max = 4\n",
    "x2_max = -(perceptron2.W[0] + perceptron2.W[1] * x1_max) / perceptron2.W[2]\n",
    "\n",
    "plt.plot([x1_min, x1_max], [x2_min, x2_max])\n",
    "plt.scatter(X[Y == -1, 1], X[Y == -1, 2], label=\"class -1\")\n",
    "plt.scatter(X[Y == 1, 1], X[Y == 1, 2], label=\"class +1\")\n",
    "plt.title('Before training')\n",
    "plt.xlabel('feature 1')\n",
    "plt.ylabel('featore 2')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(200):\n",
    "    perceptron2.train(X, Y)\n",
    "    perceptron2.evaluate(X, Y, True)\n",
    "\n",
    "print(perceptron2.W)\n",
    "\n",
    "x1_min = -4\n",
    "x2_min = -(perceptron2.W[0] + perceptron2.W[1] * x1_min) / perceptron2.W[2]\n",
    "x1_max = 4\n",
    "x2_max = -(perceptron2.W[0] + perceptron2.W[1] * x1_max) / perceptron2.W[2]\n",
    "\n",
    "plt.plot([x1_min, x1_max], [x2_min, x2_max])\n",
    "plt.scatter(X[Y == -1, 1], X[Y == -1, 2], label=\"class -1\")\n",
    "plt.scatter(X[Y == 1, 1], X[Y == 1, 2], label=\"class +1\")\n",
    "plt.title('Before training')\n",
    "plt.xlabel('feature 1')\n",
    "plt.ylabel('featore 2')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "artificial_intelligence",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
